{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Data to HDFS using Kafka Connect\n",
    "\n",
    "Let us get an overview of writing data to HDFS using Kafka Connect. Kafka provide basic connectors out of the box. If we want to use any other service than files as source or sink then we need to setup plugins.\n",
    "\n",
    "Here are the steps we need to follow.\n",
    "* Download Plugin for HDFS Sink Connector.\n",
    "* Copy to appropriate location.\n",
    "* Make sure to create standalone or distributed properties file.\n",
    "* Make sure to create properties file for HDFS sink.\n",
    "* Once the properties files are ready we can start Kafka standalone connect process by passing properties files as arguments.\n",
    "\n",
    "Let's take care of the end to end process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 2",
   "language": "python",
   "name": "pyspark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
