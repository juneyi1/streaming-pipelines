{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e553a7",
   "metadata": {},
   "source": [
    "## Write Data to HDFS using Spark\n",
    "\n",
    "Let us now write the data to HDFS using Spark Structured Streaming APIs. It will take care of writing streaming data frame to HDFS.\n",
    "\n",
    "Here are the steps that are involved.\n",
    "* Create spark session object.\n",
    "* Create streaming data frame by subscribing to Kafka topic leveraging `readStream`.\n",
    "* Apply required transformations to add new fields such as year, month and dayofmonth.\n",
    "* Write the data from streaming data frame to HDFS using appropriate format. We will be using `csv` for now. We can write data to all standard formats using streaming data frame.\n",
    "* We need to specify `checkpointLocation` while writing data to HDFS. The location should be in HDFS itself.\n",
    "* As part of this lecture we will validate whether the files are being generated or not. We will perform detailed validation as part of next lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ccbd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import getpass\n",
    "username = getpass.getuser()\n",
    "\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1'). \\\n",
    "    config('spark.ui.port', '0'). \\\n",
    "    config('spark.sql.warehouse.dir', f'/user/{username}/warehouse'). \\\n",
    "    enableHiveSupport(). \\\n",
    "    appName(f'{username} | Python - Kafka and Spark Integration'). \\\n",
    "    master('yarn'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb42327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_bootstrap_servers = 'w01.itversity.com:9092,w02.itversity.com:9092'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac8732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark. \\\n",
    "  readStream. \\\n",
    "  format('kafka'). \\\n",
    "  option('kafka.bootstrap.servers', kafka_bootstrap_servers). \\\n",
    "  option('subscribe', f'{username}_retail'). \\\n",
    "  load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae401a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_format, to_date, split, substring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a78f2610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"CAST(key AS STRING) AS key\", \"CAST(value AS STRING) AS value\").printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a55dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: `/user/itv007304/kafka/retail_logs/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -R -skipTrash /user/${USER}/kafka/retail_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fed6dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f56bafd2e48>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.selectExpr(\"CAST(value AS STRING)\"). \\\n",
    "    withColumn('log_date', to_date(substring(split('value', ' ')[3], 2, 21), '[dd/MMM/yyyy:HH:mm:ss')). \\\n",
    "    withColumn('year', date_format('log_date', 'yyyy')). \\\n",
    "    withColumn('month', date_format('log_date', 'MM')). \\\n",
    "    withColumn('dayofmonth', date_format('log_date', 'dd')). \\\n",
    "    writeStream. \\\n",
    "    partitionBy('year', 'month', 'dayofmonth'). \\\n",
    "    format('csv'). \\\n",
    "    option(\"checkpointLocation\", f'/user/{username}/kafka/retail_logs/gen_logs/checkpoint'). \\\n",
    "    option('path', f'/user/{username}/kafka/retail_logs/gen_logs/data'). \\\n",
    "    trigger(processingTime='30 seconds'). \\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76a3cfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - itversity itversity          0 2021-09-02 13:20 /user/itversity/kafka/retail_logs/gen_logs/checkpoint\n",
      "drwxr-xr-x   - itversity itversity          0 2021-09-02 13:20 /user/itversity/kafka/retail_logs/gen_logs/data\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/${USER}/kafka/retail_logs/gen_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "356232d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - itversity itversity          0 2021-09-02 13:20 /user/itversity/kafka/retail_logs/gen_logs/data/_spark_metadata\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -R /user/${USER}/kafka/retail_logs/gen_logs/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dfdd4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7ff870350198>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.selectExpr(\"CAST(value AS STRING)\"). \\\n",
    "    withColumn('log_date', to_date(substring(split('value', ' ')[3], 2, 21), '[dd/MMM/yyyy:HH:mm:ss')). \\\n",
    "    withColumn('year', date_format('log_date', 'yyyy')). \\\n",
    "    withColumn('month', date_format('log_date', 'MM')). \\\n",
    "    withColumn('dayofmonth', date_format('log_date', 'dd')). \\\n",
    "    writeStream. \\\n",
    "    partitionBy('year', 'month', 'dayofmonth'). \\\n",
    "    format('csv'). \\\n",
    "    option(\"checkpointLocation\", f'/user/{username}/kafka/retail_logs/gen_logs/checkpoint'). \\\n",
    "    option('path', f'/user/{username}/kafka/retail_logs/gen_logs/data'). \\\n",
    "    option('header', True). \\\n",
    "    option('sep', '\\t'). \\\n",
    "    trigger(processingTime='30 seconds'). \\\n",
    "    start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10014481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - itv007304 supergroup          0 2023-06-09 14:17 /user/itv007304/kafka/retail_logs/gen_logs/checkpoint\n",
      "drwxr-xr-x   - itv007304 supergroup          0 2023-06-09 14:17 /user/itv007304/kafka/retail_logs/gen_logs/data\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /user/${USER}/kafka/retail_logs/gen_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c55bb452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x   - itv007304 supergroup          0 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/_spark_metadata\n",
      "-rw-r--r--   3 itv007304 supergroup          2 2023-06-09 14:17 /user/itv007304/kafka/retail_logs/gen_logs/data/_spark_metadata/0\n",
      "-rw-r--r--   3 itv007304 supergroup        893 2023-06-09 14:25 /user/itv007304/kafka/retail_logs/gen_logs/data/_spark_metadata/1\n",
      "-rw-r--r--   3 itv007304 supergroup        893 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/_spark_metadata/2\n",
      "-rw-r--r--   3 itv007304 supergroup        893 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/_spark_metadata/3\n",
      "drwxr-xr-x   - itv007304 supergroup          0 2023-06-09 14:25 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023\n",
      "drwxr-xr-x   - itv007304 supergroup          0 2023-06-09 14:25 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02\n",
      "drwxr-xr-x   - itv007304 supergroup          0 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23\n",
      "-rw-r--r--   3 itv007304 supergroup     500474 2023-06-09 14:25 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00000-51c67fd1-0abc-43f9-97be-b5124690be59.c000.csv\n",
      "-rw-r--r--   3 itv007304 supergroup     421785 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00000-81bab0f8-5d5f-45fc-811d-da78b0133001.c000.csv\n",
      "-rw-r--r--   3 itv007304 supergroup     146549 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00000-d49ff698-806b-488d-8088-6d374a0daa3d.c000.csv\n",
      "-rw-r--r--   3 itv007304 supergroup     416328 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00001-9f9ea159-9709-4a02-b300-23c92714a588.c000.csv\n",
      "-rw-r--r--   3 itv007304 supergroup     565116 2023-06-09 14:25 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00001-b5ff7132-4735-4358-ad03-2030bc43c311.c000.csv\n",
      "-rw-r--r--   3 itv007304 supergroup     136036 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00001-c42e4321-c2a8-4c47-90e8-2027e0b1accd.c000.csv\n",
      "-rw-r--r--   3 itv007304 supergroup     468617 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00002-75452149-3185-4e7a-b7cc-3014b820c498.c000.csv\n",
      "-rw-r--r--   3 itv007304 supergroup     152709 2023-06-09 14:26 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00002-93215e39-7295-478a-9ac1-819b5d23d0a7.c000.csv\n",
      "-rw-r--r--   3 itv007304 supergroup     673529 2023-06-09 14:25 /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00002-ff8e3398-38c8-46fe-ac66-8edf68c9c05a.c000.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -R /user/${USER}/kafka/retail_logs/gen_logs/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -cat /user/itv007304/kafka/retail_logs/gen_logs/data/year=2023/month=02/dayofmonth=23/part-00002-ff8e3398-38c8-46fe-ac66-8edf68c9c05a.c000.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e886ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(f\"/user/{username}/kafka/retail_logs/gen_logs/data\", sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5706fe54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- log_date: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dayofmonth: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f14d5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----+-----+----------+\n",
      "|value                                                                                                                                                                                                                   |log_date  |year|month|dayofmonth|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----+-----+----------+\n",
      "|109.150.11.154 - - [23/Feb/2023:12:17:38 -0800] \"GET /login HTTP/1.1\" 200 283 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\"                       |2023-02-23|2023|2    |23        |\n",
      "|96.40.206.99 - - [23/Feb/2023:12:17:39 -0800] \"GET /departments HTTP/1.1\" 200 1307 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\"                  |2023-02-23|2023|2    |23        |\n",
      "|185.195.228.81 - - [23/Feb/2023:12:17:40 -0800] \"GET /department/fan%20shop/categories HTTP/1.1\" 200 1707 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:30.0) Gecko/20100101 Firefox/30.0\"                       |2023-02-23|2023|2    |23        |\n",
      "|160.118.89.54 - - [23/Feb/2023:12:17:41 -0800] \"GET /add_to_cart/913 HTTP/1.1\" 200 1884 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"             |2023-02-23|2023|2    |23        |\n",
      "|35.82.37.240 - - [23/Feb/2023:12:17:42 -0800] \"GET /department/apparel/categories HTTP/1.1\" 200 1724 \"-\" \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\"|2023-02-23|2023|2    |23        |\n",
      "|40.109.29.44 - - [23/Feb/2023:12:17:43 -0800] \"GET /department/apparel/products HTTP/1.1\" 200 2073 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\"  |2023-02-23|2023|2    |23        |\n",
      "|106.121.93.189 - - [23/Feb/2023:12:17:44 -0800] \"GET /product/546 HTTP/1.1\" 200 1121 \"-\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:30.0) Gecko/20100101 Firefox/30.0\"                                            |2023-02-23|2023|2    |23        |\n",
      "|160.47.150.137 - - [23/Feb/2023:12:17:45 -0800] \"GET /departments HTTP/1.1\" 200 481 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/35.0.1916.153 Safari/537.36\"                 |2023-02-23|2023|2    |23        |\n",
      "|106.210.172.61 - - [23/Feb/2023:12:17:46 -0800] \"GET /departments HTTP/1.1\" 200 1211 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.125 Safari/537.36\"                |2023-02-23|2023|2    |23        |\n",
      "|81.224.241.219 - - [23/Feb/2023:12:17:47 -0800] \"GET /logout HTTP/1.1\" 200 1818 \"-\" \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:30.0) Gecko/20100101 Firefox/30.0\"                                                          |2023-02-23|2023|2    |23        |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------+----+-----+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c88671",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3",
   "language": "python",
   "name": "pyspark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
